{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Loss Functions in Deep Learning**\n",
        "\n",
        "**Loss Function**\n",
        "\n",
        "A loss function measures how wrong the modelâ€™s prediction is.\n",
        "\n",
        "**In very simple words:**\n",
        "\n",
        "It tells the model how far its prediction is from the correct answer.\n",
        "\n",
        "**Why do we use loss functions?**\n",
        "\n",
        "**Without a loss function:**\n",
        "\n",
        "* The model would not know whether it is performing well or badly\n",
        "\n",
        "* There would be no direction to improve\n",
        "\n",
        "* Training would be meaningless\n",
        "\n",
        "**With a loss function:**\n",
        "\n",
        "* The model gets a numerical error value\n",
        "\n",
        "* This error is used to update weights using backpropagation\n",
        "\n",
        "* The goal of training is to minimize this loss\n",
        "\n",
        "**Simple example**\n",
        "\n",
        "Imagine shooting arrows at a target ðŸŽ¯:\n",
        "\n",
        "* Arrow hits center â†’ small loss\n",
        "\n",
        "* Arrow far from center â†’ large loss\n",
        "\n",
        "The loss function measures how far the arrow is from the center."
      ],
      "metadata": {
        "id": "cvgzsS-RVFW4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AUelu57MUuUS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **01, Mean Square Error (L2) Loss Function**\n",
        "\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(y,\\hat{y}) = \\frac{1}{n}\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
        "$$\n",
        "\n",
        "# **Derivative of MSE (L2) Loss**\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}}\n",
        "= \\frac{2}{n}(\\hat{y} - y)\n",
        "$$\n",
        "\n",
        "### **Where**\n",
        "\n",
        "- yáµ¢ is the true (actual) value  \n",
        "- Å·áµ¢ is the predicted value  \n",
        "- n is the number of samples  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zaS5EA9JV12D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean Square Error (L2 Loss)\n",
        "def mse(pridictors, actuals):\n",
        "  error = pridictors - actuals\n",
        "  squared_error = error ** 2\n",
        "  mean_squared_error = torch.mean(squared_error)\n",
        "  return mean_squared_error\n",
        "\n",
        "# Using nn Module\n",
        "mse_loss = nn.MSELoss()"
      ],
      "metadata": {
        "id": "XE65rfBeVd5z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **02, Mean Absolute Error (L1) Loss Function**\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(y,\\hat{y}) = \\frac{1}{n}\\sum_{i=1}^{n} \\big| y_i - \\hat{y}_i \\big|\n",
        "$$\n",
        "\n",
        "# **Derivative of MAE (L1) Loss**\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}_i} =\n",
        "\\frac{1}{n} \\, \\text(\\hat{y}_i - y_i)\n",
        "$$\n",
        "\n",
        "### **Where**\n",
        "\n",
        "- yáµ¢ is the true (actual) value  \n",
        "- Å·áµ¢ is the predicted value  \n",
        "- n is the number of samples  \n"
      ],
      "metadata": {
        "id": "7_AgoamAbAq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean Absolute Error (L1 Loss)\n",
        "def mae(pridictions, actuals):\n",
        "  error = torch.abs(pridictions -  actuals)\n",
        "  mean_absolute_error = torch.mean(error)\n",
        "  return mean_absolute_error\n",
        "\n",
        "# Using nn Module\n",
        "mae_loss = nn.L1Loss()"
      ],
      "metadata": {
        "id": "ExNfdGHTY1Fu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **03, Mean Bias Error (MBE) Loss Function**\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(y,\\hat{y}) = \\frac{1}{n}\\sum_{i=1}^{n} (\\hat{y}_i - y_i)\n",
        "$$\n",
        "\n",
        "# **Derivative of MBE Loss**\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}_i} = \\frac{1}{n}\n",
        "$$\n",
        "\n",
        "### **Where**\n",
        "\n",
        "- yáµ¢ is the true (actual) value  \n",
        "- Å·áµ¢ is the predicted value  \n",
        "- n is the number of samples  \n"
      ],
      "metadata": {
        "id": "_C38AZgAd2pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predications = torch.tensor([1, 2, 3, 4, 5],dtype=torch.float32)\n",
        "actuals = torch.tensor([2, 4, 6, 8, 10], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "aY79lwtrkZUi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Mean Bias Error\n",
        "\n",
        "def mbe(predictions, actuals):\n",
        "    error = predictions - actuals          # predicted - actual\n",
        "    mean_bias_error = torch.mean(error)    # take mean\n",
        "    return mean_bias_error\n",
        "\n",
        "# Calculate MBE\n",
        "mbe_cost = mbe(predications, actuals)\n",
        "print(\"MBE Loss:\", mbe_cost.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdmqzMKYc0I7",
        "outputId": "2cd2270b-3563-4dad-8459-aa86519203e7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MBE Loss: -3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **04, Root Mean Squared Error (RMSE) Loss Function**\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(y,\\hat{y}) = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "# **Derivative of RMSE Loss**\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}_i} = \\frac{1}{n \\, \\mathcal{L}(y,\\hat{y})} (\\hat{y}_i - y_i)\n",
        "$$\n",
        "\n",
        "### **Where**\n",
        "\n",
        "- yáµ¢ is the true (actual) value  \n",
        "- Å·áµ¢ is the predicted value  \n",
        "- n is the number of samples  \n"
      ],
      "metadata": {
        "id": "zhWU8IgGhAUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Root Mean Squared Error\n",
        "\n",
        "def rmse(predictions, actuals):\n",
        "    error = (predictions - actuals) ** 2          # predicted - actual\n",
        "    mean_squared_error = torch.mean(error)    # take mean\n",
        "    root_mean_squared_error = torch.sqrt(mean_squared_error)\n",
        "    return root_mean_squared_error\n",
        "\n",
        "\n",
        "# Calculate MBE\n",
        "mbe_cost = rmse(predications, actuals)\n",
        "print(\"MBE Loss:\", mbe_cost.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXiI67r2eor2",
        "outputId": "54f80f15-2c31-4d4b-ff83-6e627acced1c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MBE Loss: 3.316624879837036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **05, Root Mean Squared Logarithmic Error (RMSLE) Loss Function**\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(y,\\hat{y}) = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} \\big( \\log(\\hat{y}_i + 1) - \\log(y_i + 1) \\big)^2}\n",
        "$$\n",
        "\n",
        "# **Derivative of RMSLE Loss**\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}_i} =\n",
        "\\frac{1}{n \\, \\mathcal{L}(y,\\hat{y})} \\cdot \\frac{\\log(\\hat{y}_i + 1) - \\log(y_i + 1)}{\\hat{y}_i + 1}\n",
        "$$\n",
        "\n",
        "### **Where**\n",
        "\n",
        "- yáµ¢ is the true (actual) value  \n",
        "- Å·áµ¢ is the predicted value  \n",
        "- n is the number of samples  \n"
      ],
      "metadata": {
        "id": "eWJvX0irjy1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "predictions = torch.tensor([2.5, 5.0, 4.0])\n",
        "actuals     = torch.tensor([3.0, 5.2, 4.1])\n",
        "\n",
        "\n",
        "# Root Mean Squared Logarithmic Error (RMSLE) from scratch\n",
        "\n",
        "def rmsle(predictions, actuals):\n",
        "    # Add 1 to avoid log(0)\n",
        "    log_pred = torch.log(predictions + 1)\n",
        "    log_actual = torch.log(actuals + 1)\n",
        "\n",
        "    error = (log_pred - log_actual) ** 2            # squared log error\n",
        "    mean_squared_log_error = torch.mean(error)      # take mean\n",
        "    root_mean_squared_log_error = torch.sqrt(mean_squared_log_error)  # sqrt\n",
        "    return root_mean_squared_log_error\n",
        "\n",
        "# Calculate RMSLE\n",
        "rmsle_cost = rmsle(predictions, actuals)\n",
        "print(\"RMSLE Loss:\", rmsle_cost.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiQZmK_3hju_",
        "outputId": "d0d101ee-6c47-4ae3-9cbf-7999a4b745c7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSLE Loss: 0.08020374923944473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **06, Huber Loss Function**\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(y,\\hat{y}) =\n",
        "\\begin{cases}\n",
        "\\frac{1}{2}(y_i - \\hat{y}_i)^2 & \\text{if } |y_i - \\hat{y}_i| \\le \\delta \\\\\n",
        "\\delta \\cdot \\big(|y_i - \\hat{y}_i| - \\frac{1}{2}\\delta\\big) & \\text{otherwise}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "# **Derivative of Huber Loss**\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}_i} =\n",
        "\\begin{cases}\n",
        "\\hat{y}_i - y_i & \\text{if } |y_i - \\hat{y}_i| \\le \\delta \\\\\n",
        "\\delta \\cdot \\text{sign}(\\hat{y}_i - y_i) & \\text{otherwise}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "### **Where**\n",
        "\n",
        "- yáµ¢ is the true (actual) value  \n",
        "- Å·áµ¢ is the predicted value  \n",
        "- n is the number of samples  \n",
        "- Î´ is the threshold parameter separating L1 and L2 behavior  \n"
      ],
      "metadata": {
        "id": "gfeTc4Y9rgs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Huber Loss from scratch\n",
        "def huber_loss(predictions, actuals, delta=1.0):\n",
        "    error = predictions - actuals\n",
        "    abs_error = torch.abs(error)\n",
        "\n",
        "    # Huber formula\n",
        "    loss = torch.where(abs_error <= delta,\n",
        "                       0.5 * error ** 2,\n",
        "                       delta * (abs_error - 0.5 * delta))\n",
        "\n",
        "    return torch.mean(loss)\n",
        "\n",
        "# Calculate Huber Loss\n",
        "huber_cost = huber_loss(predictions, actuals, delta=1.0)\n",
        "print(\"Huber Loss:\", huber_cost.item())\n",
        "\n",
        "\n",
        "# Using nn module\n",
        "huber_loss = nn.HuberLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06REsVNRkNQc",
        "outputId": "540f08ab-8f5a-4126-c2c1-a145052167f2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Huber Loss: 0.049999985843896866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **07, Log-Cosh Loss Function**\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(y,\\hat{y}) = \\frac{1}{n} \\sum_{i=1}^{n} \\log\\big(\\cosh(\\hat{y}_i - y_i)\\big)\n",
        "$$\n",
        "\n",
        "# **Derivative of Log-Cosh Loss**\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}_i} = \\frac{1}{n} \\tanh(\\hat{y}_i - y_i)\n",
        "$$\n",
        "\n",
        "### **Where**\n",
        "\n",
        "- yáµ¢ is the true (actual) value  \n",
        "- Å·áµ¢ is the predicted value  \n",
        "- n is the number of samples  \n"
      ],
      "metadata": {
        "id": "F9DdsFfXufbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Log-Cosh Loss from scratch\n",
        "def log_cosh_loss(predictions, actuals):\n",
        "    error = predictions - actuals\n",
        "    loss = torch.log(torch.cosh(error))  # element-wise log-cosh\n",
        "    return torch.mean(loss)\n",
        "\n",
        "# Calculate Log-Cosh Loss\n",
        "log_cosh_cost = log_cosh_loss(predictions, actuals)\n",
        "print(\"Log-Cosh Loss:\", log_cosh_cost.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySVNN_9rsBaN",
        "outputId": "3b9c7389-353c-4b62-9dd5-46289a1522da"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log-Cosh Loss: 0.048324745148420334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classification Loss Functions**\n",
        "\n",
        "## **08, Binary Cross-Entropy (BCE) Loss Function**\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(y,\\hat{y}) = - \\frac{1}{n} \\sum_{i=1}^{n} \\Big[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) \\Big]\n",
        "$$\n",
        "\n",
        "## **Derivative of BCE Loss**\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}_i} =\n",
        "- \\frac{1}{n} \\left( \\frac{y_i}{\\hat{y}_i} - \\frac{1 - y_i}{1 - \\hat{y}_i} \\right)\n",
        "$$\n",
        "\n",
        "### **Where**\n",
        "\n",
        "- yáµ¢ is the true (actual) label (0 or 1)  \n",
        "- Å·áµ¢ is the predicted probability  \n",
        "- n is the number of samples  \n"
      ],
      "metadata": {
        "id": "DhxJxLf9RNLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "predictions = torch.tensor([2.5, 5.0, 4.0])\n",
        "actuals     = torch.tensor([3.0, 5.2, 4.1])\n",
        "\n",
        "# BCE\n",
        "def bce(predictions, actuals):\n",
        "  epsilon = 1e-7 # to avoid log zero\n",
        "  predications = torch.clamp(predications, epsilon, 1- epsilon)\n",
        "  bce_loss = -torch.mean (actuals * torch.log(predictions) + (1 - actuals) * torch.log(1 - predictions))\n",
        "  return bce_loss\n",
        "\n",
        "# bce = bce(predications, actuals)\n",
        "# print(\"BCE Loss:\", bce.item())\n",
        "\n",
        "# Using nn module\n",
        "bce_loss = nn.BCELoss()\n",
        "\n"
      ],
      "metadata": {
        "id": "ivwbEMQFuxIT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **09, Categorical Cross-Entropy (CCE) Loss Function**\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(y,\\hat{y}) = - \\frac{1}{n} \\sum_{i=1}^{n} \\sum_{c=1}^{C} y_{i,c} \\log(\\hat{y}_{i,c})\n",
        "$$\n",
        "\n",
        "# **Derivative of CCE Loss**\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}_{i,c}} = - \\frac{1}{n} \\frac{y_{i,c}}{\\hat{y}_{i,c}}\n",
        "$$\n",
        "\n",
        "### **Where**\n",
        "\n",
        "- yáµ¢,ðšŒ is the one-hot encoded true label for class c  \n",
        "- Å·áµ¢,ðšŒ is the predicted probability for class c  \n",
        "- n is the number of samples  \n",
        "- C is the number of classes  \n"
      ],
      "metadata": {
        "id": "rzanYztbU5q3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Sample data (batch_size=3, num_classes=3)\n",
        "predictions = torch.tensor([[0.2, 0.5, 0.3],\n",
        "                            [0.1, 0.8, 0.1],\n",
        "                            [0.7, 0.2, 0.1]], dtype=torch.float32)\n",
        "actuals     = torch.tensor([[0, 1, 0],\n",
        "                            [0, 1, 0],\n",
        "                            [1, 0, 0]], dtype=torch.float32)  # one-hot encoded\n",
        "\n",
        "# -----------------------------\n",
        "# Categorical Cross-Entropy (CCE) from scratch\n",
        "# -----------------------------\n",
        "def cce(predictions, actuals):\n",
        "    epsilon = 1e-7  # to avoid log(0)\n",
        "    predictions = torch.clamp(predictions, epsilon, 1 - epsilon)\n",
        "    loss = -torch.mean(torch.sum(actuals * torch.log(predictions), dim=1))\n",
        "    return loss\n",
        "\n",
        "# Calculate CCE\n",
        "cce_loss_value = cce(predictions, actuals)\n",
        "print(\"CCE Loss:\", cce_loss_value.item())\n",
        "\n",
        "# -----------------------------\n",
        "# Using nn Module\n",
        "# -----------------------------\n",
        "cce_loss = nn.CrossEntropyLoss()  # expects class indices, not one-hot\n",
        "# Example for nn.CrossEntropyLoss, convert actuals to class indices\n",
        "targets = torch.tensor([1, 1, 0])  # class indices\n",
        "loss_nn = cce_loss(predictions, targets)\n",
        "print(\"CCE Loss (nn.Module):\", loss_nn.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIe2iQ_zSXy4",
        "outputId": "a1b74284-529d-4464-e9ba-d420eaca2bcd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CCE Loss: 0.42432188987731934\n",
            "CCE Loss (nn.Module): 0.79916912317276\n"
          ]
        }
      ]
    }
  ]
}